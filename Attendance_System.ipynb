{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attendance_System.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers,models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image_folder):\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    for label,person_name in enumerate(os.listdir(image_folder)):\n",
    "        person_path=os.path.join(image_folder,person_name)\n",
    "        for img_file in os.listdir(person_path):\n",
    "            img_path=os.path.join(person_path,img_file)\n",
    "            img=cv2.imread(img_path)\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            img=cv2.resize(img,(128,128))  # Resize images\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    images=np.array(images).reshape(-1,128,128,1)  # Add channel for CNN\n",
    "    labels=np.array(labels)\n",
    "    return images,labels\n",
    "X_faces,y_faces=preprocess_images('data/students/')\n",
    "X_train,X_val,y_train,y_val=train_test_split(X_faces,y_faces,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a CNN model for face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model=models.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(len(np.unique(y_faces)),activation='softmax')\n",
    "])\n",
    "face_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "face_model.fit(X_train,y_train,epochs=10,validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained face recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model.save('models/face_recognition_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_emotions(image_folder):\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    for label,emotion_name in enumerate(os.listdir(image_folder)):\n",
    "        emotion_path=os.path.join(image_folder,emotion_name)\n",
    "        for img_file in os.listdir(emotion_path):\n",
    "            img_path=os.path.join(emotion_path,img_file)\n",
    "            img=cv2.imread(img_path)\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            img=cv2.resize(img,(48,48))  # Resize images for emotion detection\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    images=np.array(images).reshape(-1,48,48,1)\n",
    "    labels=np.array(labels)\n",
    "    return images,labels\n",
    "X_emotions,y_emotions=preprocess_emotions('data/emotions/')\n",
    "X_train_emotions,X_val_emotions,y_train_emotions,y_val_emotions=train_test_split(X_emotions,y_emotions,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a CNN model for emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model=models.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(48,48,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(7,activation='softmax')  #any 7 emotions like happy, sad, etc.\n",
    "])\n",
    "emotion_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "emotion_model.fit(X_train_emotions,y_train_emotions,epochs=10,validation_data=(X_val_emotions,y_val_emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained emotion detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.save('models/emotion_detection_model.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
